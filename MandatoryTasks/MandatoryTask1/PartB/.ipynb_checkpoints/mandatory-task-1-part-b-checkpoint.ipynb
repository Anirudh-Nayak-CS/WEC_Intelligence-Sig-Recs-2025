{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:32:15.450907Z",
     "iopub.status.busy": "2025-10-21T18:32:15.450616Z",
     "iopub.status.idle": "2025-10-21T18:32:21.148566Z",
     "shell.execute_reply": "2025-10-21T18:32:21.147778Z",
     "shell.execute_reply.started": "2025-10-21T18:32:15.450879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Downloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 1.0.0rc2\n",
      "    Uninstalling huggingface-hub-1.0.0rc2:\n",
      "      Successfully uninstalled huggingface-hub-1.0.0rc2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.35.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:32:27.472105Z",
     "iopub.status.busy": "2025-10-21T18:32:27.471831Z",
     "iopub.status.idle": "2025-10-21T18:32:53.509670Z",
     "shell.execute_reply": "2025-10-21T18:32:53.509049Z",
     "shell.execute_reply.started": "2025-10-21T18:32:27.472080Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 18:32:41.434709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761071561.631862      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761071561.688899      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import huggingface_hub\n",
    "import peft\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:32:53.511635Z",
     "iopub.status.busy": "2025-10-21T18:32:53.510788Z",
     "iopub.status.idle": "2025-10-21T18:32:55.883614Z",
     "shell.execute_reply": "2025-10-21T18:32:55.882659Z",
     "shell.execute_reply.started": "2025-10-21T18:32:53.511615Z"
    },
    "id": "6Wd1oGlwwvS6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_parquet(\"hf://datasets/Helsinki-NLP/opus_books/en-fr/train-00000-of-00001.parquet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:09.942058Z",
     "iopub.status.busy": "2025-10-21T18:33:09.941497Z",
     "iopub.status.idle": "2025-10-21T18:33:09.948454Z",
     "shell.execute_reply": "2025-10-21T18:33:09.947485Z",
     "shell.execute_reply.started": "2025-10-21T18:33:09.942035Z"
    },
    "id": "YSZH8c8A-zrY",
    "outputId": "09482acd-c78a-460b-d08c-542fb31b941a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127085"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:10.146008Z",
     "iopub.status.busy": "2025-10-21T18:33:10.145757Z",
     "iopub.status.idle": "2025-10-21T18:33:10.149924Z",
     "shell.execute_reply": "2025-10-21T18:33:10.149158Z",
     "shell.execute_reply.started": "2025-10-21T18:33:10.145981Z"
    },
    "id": "wu_HoTIODcQS",
    "outputId": "22eef4ee-cf26-4d2a-86b1-23884d518d3f"
   },
   "outputs": [],
   "source": [
    "train_df=train_df[0:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:10.350579Z",
     "iopub.status.busy": "2025-10-21T18:33:10.350105Z",
     "iopub.status.idle": "2025-10-21T18:33:10.356265Z",
     "shell.execute_reply": "2025-10-21T18:33:10.355699Z",
     "shell.execute_reply.started": "2025-10-21T18:33:10.350559Z"
    },
    "id": "h-fd7lGKD44e",
    "outputId": "69730a1f-467c-42ea-e20c-5306423ebfcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    {'en': 'First Part', 'fr': 'PREMIÈRE PARTIE'}\n",
       "Name: translation, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[2:3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:12.705822Z",
     "iopub.status.busy": "2025-10-21T18:33:12.705545Z",
     "iopub.status.idle": "2025-10-21T18:33:12.709858Z",
     "shell.execute_reply": "2025-10-21T18:33:12.709130Z",
     "shell.execute_reply.started": "2025-10-21T18:33:12.705801Z"
    },
    "id": "HQ51eywkD4gz"
   },
   "outputs": [],
   "source": [
    "train_end=int(0.6*len(train_df))\n",
    "valid_end=int(0.8*len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:12.909954Z",
     "iopub.status.busy": "2025-10-21T18:33:12.909561Z",
     "iopub.status.idle": "2025-10-21T18:33:12.914563Z",
     "shell.execute_reply": "2025-10-21T18:33:12.913812Z",
     "shell.execute_reply.started": "2025-10-21T18:33:12.909933Z"
    },
    "id": "B2_4H0jBjNji",
    "outputId": "851e3cfa-9217-4438-ff5c-37f44b698674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'The Wanderer', 'fr': 'Le grand Meaulnes'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:13.114638Z",
     "iopub.status.busy": "2025-10-21T18:33:13.114404Z",
     "iopub.status.idle": "2025-10-21T18:33:13.140867Z",
     "shell.execute_reply": "2025-10-21T18:33:13.140283Z",
     "shell.execute_reply.started": "2025-10-21T18:33:13.114621Z"
    },
    "id": "8Oz_GTxCj2tp",
    "outputId": "2b4bd919-7898-4edf-a725-20f15a55e755"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'en': 'The Wanderer', 'fr': 'Le grand Meaulnes'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'en': 'Alain-Fournier', 'fr': 'Alain-Fournier'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>{'en': 'First Part', 'fr': 'PREMIÈRE PARTIE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>{'en': 'I', 'fr': 'CHAPITRE PREMIER'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>{'en': 'THE BOARDER', 'fr': 'LE PENSIONNAIRE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>{'en': '\"I should not mind anything at all.\"',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>{'en': '\"Let us be thankful that you are prese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>{'en': '\"I never can be thankful, Mr. Bennet, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>{'en': 'How anyone could have the conscience t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>{'en': 'Why should _he_ have it more than anyb...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        translation\n",
       "0        0  {'en': 'The Wanderer', 'fr': 'Le grand Meaulnes'}\n",
       "1        1   {'en': 'Alain-Fournier', 'fr': 'Alain-Fournier'}\n",
       "2        2      {'en': 'First Part', 'fr': 'PREMIÈRE PARTIE'}\n",
       "3        3              {'en': 'I', 'fr': 'CHAPITRE PREMIER'}\n",
       "4        4     {'en': 'THE BOARDER', 'fr': 'LE PENSIONNAIRE'}\n",
       "...    ...                                                ...\n",
       "4995  4995  {'en': '\"I should not mind anything at all.\"',...\n",
       "4996  4996  {'en': '\"Let us be thankful that you are prese...\n",
       "4997  4997  {'en': '\"I never can be thankful, Mr. Bennet, ...\n",
       "4998  4998  {'en': 'How anyone could have the conscience t...\n",
       "4999  4999  {'en': 'Why should _he_ have it more than anyb...\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:13.221712Z",
     "iopub.status.busy": "2025-10-21T18:33:13.221037Z",
     "iopub.status.idle": "2025-10-21T18:33:13.227289Z",
     "shell.execute_reply": "2025-10-21T18:33:13.226557Z",
     "shell.execute_reply.started": "2025-10-21T18:33:13.221686Z"
    },
    "id": "z9wmxTuikWC_",
    "outputId": "b13847c9-6091-4d40-d0ed-01ac48496961"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'en': 'The Wanderer', 'fr': 'Le grand Meaulnes'}\n",
       "1     {'en': 'Alain-Fournier', 'fr': 'Alain-Fournier'}\n",
       "2        {'en': 'First Part', 'fr': 'PREMIÈRE PARTIE'}\n",
       "3                {'en': 'I', 'fr': 'CHAPITRE PREMIER'}\n",
       "Name: translation, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[:4,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:13.421916Z",
     "iopub.status.busy": "2025-10-21T18:33:13.421716Z",
     "iopub.status.idle": "2025-10-21T18:33:13.425634Z",
     "shell.execute_reply": "2025-10-21T18:33:13.425078Z",
     "shell.execute_reply.started": "2025-10-21T18:33:13.421901Z"
    },
    "id": "Go-Qud-cDafX"
   },
   "outputs": [],
   "source": [
    "train_text=train_df.iloc[:train_end,1]\n",
    "val_text=train_df.iloc[train_end:valid_end,1]\n",
    "test_text=train_df.iloc[valid_end:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:13.626850Z",
     "iopub.status.busy": "2025-10-21T18:33:13.626621Z",
     "iopub.status.idle": "2025-10-21T18:33:13.631391Z",
     "shell.execute_reply": "2025-10-21T18:33:13.630834Z",
     "shell.execute_reply.started": "2025-10-21T18:33:13.626833Z"
    },
    "id": "d9P0sTeaFpvE",
    "outputId": "b0d52c39-4b66-4fd0-9a01-cad296c2f91b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREMIÈRE PARTIE'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.iloc[2]['fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:13.743787Z",
     "iopub.status.busy": "2025-10-21T18:33:13.743587Z",
     "iopub.status.idle": "2025-10-21T18:33:13.784820Z",
     "shell.execute_reply": "2025-10-21T18:33:13.784266Z",
     "shell.execute_reply.started": "2025-10-21T18:33:13.743772Z"
    },
    "id": "8HCORB-JlmHB"
   },
   "outputs": [],
   "source": [
    "train_text_en=[]\n",
    "for i in range(len(train_text)):\n",
    "  train_text_en.append(train_text.iloc[i]['en'])\n",
    "\n",
    "train_text_fr=[]\n",
    "for i in range(len(train_text)):\n",
    "  train_text_fr.append(train_text.iloc[i]['fr'])\n",
    "\n",
    "valid_text_en=[]\n",
    "for i in range(len(val_text)):\n",
    "  valid_text_en.append(val_text.iloc[i]['en'])\n",
    "\n",
    "valid_text_fr=[]\n",
    "for i in range(len(val_text)):\n",
    "  valid_text_fr.append(val_text.iloc[i]['fr'])\n",
    "\n",
    "    \n",
    "test_text_en=[]\n",
    "for i in range(len(test_text)):\n",
    "  test_text_en.append(test_text.iloc[i]['en'])\n",
    "\n",
    "test_text_fr=[]\n",
    "for i in range(len(test_text)):\n",
    "  test_text_fr.append(test_text.iloc[i]['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:16.375451Z",
     "iopub.status.busy": "2025-10-21T18:33:16.375172Z",
     "iopub.status.idle": "2025-10-21T18:33:16.380140Z",
     "shell.execute_reply": "2025-10-21T18:33:16.379458Z",
     "shell.execute_reply.started": "2025-10-21T18:33:16.375432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Le grand Meaulnes'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_fr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:16.494304Z",
     "iopub.status.busy": "2025-10-21T18:33:16.493734Z",
     "iopub.status.idle": "2025-10-21T18:33:16.519652Z",
     "shell.execute_reply": "2025-10-21T18:33:16.518953Z",
     "shell.execute_reply.started": "2025-10-21T18:33:16.494284Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict \n",
    "\n",
    "train_ds=Dataset.from_dict({\n",
    "    \"en\":train_text_en,\n",
    "    \"fr\":train_text_fr,\n",
    "})\n",
    "valid_ds=Dataset.from_dict({\n",
    "    \"en\":valid_text_en,\n",
    "    \"fr\":valid_text_fr,\n",
    "})\n",
    "test_ds=Dataset.from_dict({\n",
    "    'en':test_text_en,\n",
    "    'fr':test_text_fr,\n",
    "})\n",
    "\n",
    "raw_ds=DatasetDict({\n",
    "    \"train\":train_ds,\n",
    "    \"validation\":valid_ds,\n",
    "    \"test\":test_ds,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetuning T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QS7IdxxxxEV"
   },
   "source": [
    "### T-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:17.006102Z",
     "iopub.status.busy": "2025-10-21T18:33:17.005667Z",
     "iopub.status.idle": "2025-10-21T18:33:17.009344Z",
     "shell.execute_reply": "2025-10-21T18:33:17.008662Z",
     "shell.execute_reply.started": "2025-10-21T18:33:17.006082Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name =\"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:17.112186Z",
     "iopub.status.busy": "2025-10-21T18:33:17.111785Z",
     "iopub.status.idle": "2025-10-21T18:33:17.127705Z",
     "shell.execute_reply": "2025-10-21T18:33:17.126930Z",
     "shell.execute_reply.started": "2025-10-21T18:33:17.112171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d849beb8c4eb4d709d7e92846d725beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:24.429105Z",
     "iopub.status.busy": "2025-10-21T18:33:24.428372Z",
     "iopub.status.idle": "2025-10-21T18:33:24.434197Z",
     "shell.execute_reply": "2025-10-21T18:33:24.433235Z",
     "shell.execute_reply.started": "2025-10-21T18:33:24.429080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'fr'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:24.650010Z",
     "iopub.status.busy": "2025-10-21T18:33:24.649563Z",
     "iopub.status.idle": "2025-10-21T18:33:27.075169Z",
     "shell.execute_reply": "2025-10-21T18:33:27.074362Z",
     "shell.execute_reply.started": "2025-10-21T18:33:24.649987Z"
    },
    "id": "EUeVhKh_vmfH"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3183c1e924b47a3ac4c4e2bd8d2420e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68343467e0474f40bf39bdbb917fa27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d254d085a02457599c202182646952c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from transformers import AutoModelForSeq2SeqLM, T5Tokenizer,Seq2SeqTrainingArguments,DataCollatorForSeq2Seq,Seq2SeqTrainer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    \"t5-base\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:27.076693Z",
     "iopub.status.busy": "2025-10-21T18:33:27.076357Z",
     "iopub.status.idle": "2025-10-21T18:33:27.081328Z",
     "shell.execute_reply": "2025-10-21T18:33:27.080607Z",
     "shell.execute_reply.started": "2025-10-21T18:33:27.076675Z"
    }
   },
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(example):\n",
    "    inputs = [\"translate English to French: \"+ s for s in example[\"en\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target= [s for s in example[\"fr\"]], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:27.082476Z",
     "iopub.status.busy": "2025-10-21T18:33:27.082132Z",
     "iopub.status.idle": "2025-10-21T18:33:29.119262Z",
     "shell.execute_reply": "2025-10-21T18:33:29.118675Z",
     "shell.execute_reply.started": "2025-10-21T18:33:27.082455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42044d02023e4ac0b7aefb8340f872dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1b6f38ce2c454e9872c1783d048a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a53a52b88442cf826ee921d8129e5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset=raw_ds.map(preprocess_function,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:33:30.724159Z",
     "iopub.status.busy": "2025-10-21T18:33:30.723409Z",
     "iopub.status.idle": "2025-10-21T18:33:30.728500Z",
     "shell.execute_reply": "2025-10-21T18:33:30.727816Z",
     "shell.execute_reply.started": "2025-10-21T18:33:30.724132Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'fr', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'fr', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'fr', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:07.506592Z",
     "iopub.status.busy": "2025-10-21T18:37:07.506015Z",
     "iopub.status.idle": "2025-10-21T18:37:07.515289Z",
     "shell.execute_reply": "2025-10-21T18:37:07.514660Z",
     "shell.execute_reply.started": "2025-10-21T18:37:07.506569Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_dataset=tokenized_dataset.remove_columns([\"en\", \"fr\"])\n",
    "\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "\n",
    "train_pytorch_dataset = tokenized_dataset[\"train\"]\n",
    "eval_pytorch_dataset = tokenized_dataset[\"validation\"]\n",
    "test_pytorch_dataset=tokenized_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:08.841191Z",
     "iopub.status.busy": "2025-10-21T18:37:08.840697Z",
     "iopub.status.idle": "2025-10-21T18:37:09.543861Z",
     "shell.execute_reply": "2025-10-21T18:37:09.543251Z",
     "shell.execute_reply.started": "2025-10-21T18:37:08.841169Z"
    }
   },
   "outputs": [],
   "source": [
    "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    \"t5-base\"\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:09.545388Z",
     "iopub.status.busy": "2025-10-21T18:37:09.545098Z",
     "iopub.status.idle": "2025-10-21T18:37:09.549121Z",
     "shell.execute_reply": "2025-10-21T18:37:09.548364Z",
     "shell.execute_reply.started": "2025-10-21T18:37:09.545363Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator=DataCollatorForSeq2Seq(tokenizer,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:09.558421Z",
     "iopub.status.busy": "2025-10-21T18:37:09.558159Z",
     "iopub.status.idle": "2025-10-21T18:37:09.563252Z",
     "shell.execute_reply": "2025-10-21T18:37:09.562549Z",
     "shell.execute_reply.started": "2025-10-21T18:37:09.558405Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size=16\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_pytorch_dataset, batch_size=batch_size, shuffle=True,collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(eval_pytorch_dataset, batch_size=batch_size,collate_fn=data_collator)\n",
    "test_dataloader=DataLoader(test_pytorch_dataset, batch_size=batch_size,collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:12.114540Z",
     "iopub.status.busy": "2025-10-21T18:37:12.113976Z",
     "iopub.status.idle": "2025-10-21T18:37:12.118888Z",
     "shell.execute_reply": "2025-10-21T18:37:12.118299Z",
     "shell.execute_reply.started": "2025-10-21T18:37:12.114518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:12.219134Z",
     "iopub.status.busy": "2025-10-21T18:37:12.218942Z",
     "iopub.status.idle": "2025-10-21T18:37:12.224325Z",
     "shell.execute_reply": "2025-10-21T18:37:12.223641Z",
     "shell.execute_reply.started": "2025-10-21T18:37:12.219118Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs=10\n",
    "optimizer=optim.AdamW(params=model.parameters(),lr=5e-5,)\n",
    "num_training_steps=len(train_dataloader)*epochs \n",
    "num_warmup_steps=int(0.1*num_training_steps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:12.458920Z",
     "iopub.status.busy": "2025-10-21T18:37:12.458721Z",
     "iopub.status.idle": "2025-10-21T18:37:12.462483Z",
     "shell.execute_reply": "2025-10-21T18:37:12.461732Z",
     "shell.execute_reply.started": "2025-10-21T18:37:12.458906Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "lr_scheduler=get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-21T18:37:12.640917Z",
     "iopub.status.busy": "2025-10-21T18:37:12.640710Z",
     "iopub.status.idle": "2025-10-21T19:04:32.595504Z",
     "shell.execute_reply": "2025-10-21T19:04:32.594670Z",
     "shell.execute_reply.started": "2025-10-21T18:37:12.640892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/data/data_collator.py:741: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gone through 0/3008 training examples |  train_loss: 1.8534969091415405\n",
      "gone through 320/3008 training examples |  train_loss: 1.5375875234603882\n",
      "gone through 640/3008 training examples |  train_loss: 1.6362528800964355\n",
      "gone through 960/3008 training examples |  train_loss: 1.7704339027404785\n",
      "gone through 1280/3008 training examples |  train_loss: 1.3295114040374756\n",
      "gone through 1600/3008 training examples |  train_loss: 1.4441139698028564\n",
      "gone through 1920/3008 training examples |  train_loss: 1.8233203887939453\n",
      "gone through 2240/3008 training examples |  train_loss: 1.6745809316635132\n",
      "gone through 2560/3008 training examples |  train_loss: 1.579619288444519\n",
      "gone through 2880/3008 training examples |  train_loss: 1.4204888343811035\n",
      "gone through 0/1008 validation examples | eval_loss: 1.455564022064209\n",
      "gone through 160/1008 validation examples | eval_loss: 1.2468788623809814\n",
      "gone through 320/1008 validation examples | eval_loss: 1.1555016040802002\n",
      "gone through 480/1008 validation examples | eval_loss: 2.376922130584717\n",
      "gone through 640/1008 validation examples | eval_loss: 2.0612988471984863\n",
      "gone through 800/1008 validation examples | eval_loss: 2.2250816822052\n",
      "gone through 960/1008 validation examples | eval_loss: 2.0356361865997314\n",
      "After 1 epochs |  train_loss : 1.6484035849571228 |  eval_loss: 1.7963447258585976\n",
      "gone through 0/3008 training examples |  train_loss: 1.5624889135360718\n",
      "gone through 320/3008 training examples |  train_loss: 1.306949257850647\n",
      "gone through 640/3008 training examples |  train_loss: 1.276188611984253\n",
      "gone through 960/3008 training examples |  train_loss: 1.5019375085830688\n",
      "gone through 1280/3008 training examples |  train_loss: 1.3631110191345215\n",
      "gone through 1600/3008 training examples |  train_loss: 1.5151619911193848\n",
      "gone through 1920/3008 training examples |  train_loss: 1.4984830617904663\n",
      "gone through 2240/3008 training examples |  train_loss: 1.5126354694366455\n",
      "gone through 2560/3008 training examples |  train_loss: 1.433384656906128\n",
      "gone through 2880/3008 training examples |  train_loss: 1.402637004852295\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3955742120742798\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1926027536392212\n",
      "gone through 320/1008 validation examples | eval_loss: 1.058868169784546\n",
      "gone through 480/1008 validation examples | eval_loss: 2.3944125175476074\n",
      "gone through 640/1008 validation examples | eval_loss: 2.052386522293091\n",
      "gone through 800/1008 validation examples | eval_loss: 2.2246689796447754\n",
      "gone through 960/1008 validation examples | eval_loss: 2.0512139797210693\n",
      "After 2 epochs |  train_loss : 1.4218308171059222 |  eval_loss: 1.7828878836026267\n",
      "gone through 0/3008 training examples |  train_loss: 1.473666787147522\n",
      "gone through 320/3008 training examples |  train_loss: 1.3591499328613281\n",
      "gone through 640/3008 training examples |  train_loss: 1.1312533617019653\n",
      "gone through 960/3008 training examples |  train_loss: 1.3355426788330078\n",
      "gone through 1280/3008 training examples |  train_loss: 1.3819633722305298\n",
      "gone through 1600/3008 training examples |  train_loss: 1.2644513845443726\n",
      "gone through 1920/3008 training examples |  train_loss: 1.52189302444458\n",
      "gone through 2240/3008 training examples |  train_loss: 1.5470616817474365\n",
      "gone through 2560/3008 training examples |  train_loss: 1.4039989709854126\n",
      "gone through 2880/3008 training examples |  train_loss: 1.3291010856628418\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3680696487426758\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1672354936599731\n",
      "gone through 320/1008 validation examples | eval_loss: 1.012633204460144\n",
      "gone through 480/1008 validation examples | eval_loss: 2.4102673530578613\n",
      "gone through 640/1008 validation examples | eval_loss: 2.0693914890289307\n",
      "gone through 800/1008 validation examples | eval_loss: 2.2406532764434814\n",
      "gone through 960/1008 validation examples | eval_loss: 2.0692055225372314\n",
      "After 3 epochs |  train_loss : 1.3197577811302024 |  eval_loss: 1.7830985235789465\n",
      "gone through 0/3008 training examples |  train_loss: 1.3926351070404053\n",
      "gone through 320/3008 training examples |  train_loss: 1.0816798210144043\n",
      "gone through 640/3008 training examples |  train_loss: 1.1309518814086914\n",
      "gone through 960/3008 training examples |  train_loss: 1.3549288511276245\n",
      "gone through 1280/3008 training examples |  train_loss: 1.33650803565979\n",
      "gone through 1600/3008 training examples |  train_loss: 1.3100870847702026\n",
      "gone through 1920/3008 training examples |  train_loss: 1.5026450157165527\n",
      "gone through 2240/3008 training examples |  train_loss: 1.2272320985794067\n",
      "gone through 2560/3008 training examples |  train_loss: 1.0831674337387085\n",
      "gone through 2880/3008 training examples |  train_loss: 1.0884734392166138\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3582898378372192\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1374621391296387\n",
      "gone through 320/1008 validation examples | eval_loss: 0.9876763820648193\n",
      "gone through 480/1008 validation examples | eval_loss: 2.4312775135040283\n",
      "gone through 640/1008 validation examples | eval_loss: 2.0906260013580322\n",
      "gone through 800/1008 validation examples | eval_loss: 2.2623486518859863\n",
      "gone through 960/1008 validation examples | eval_loss: 2.0867016315460205\n",
      "After 4 epochs |  train_loss : 1.243373731349377 |  eval_loss: 1.7936377913232833\n",
      "gone through 0/3008 training examples |  train_loss: 1.145268201828003\n",
      "gone through 320/3008 training examples |  train_loss: 1.1620616912841797\n",
      "gone through 640/3008 training examples |  train_loss: 1.2320996522903442\n",
      "gone through 960/3008 training examples |  train_loss: 1.1606147289276123\n",
      "gone through 1280/3008 training examples |  train_loss: 1.1958770751953125\n",
      "gone through 1600/3008 training examples |  train_loss: 1.223257064819336\n",
      "gone through 1920/3008 training examples |  train_loss: 1.1576504707336426\n",
      "gone through 2240/3008 training examples |  train_loss: 1.1121498346328735\n",
      "gone through 2560/3008 training examples |  train_loss: 1.3745923042297363\n",
      "gone through 2880/3008 training examples |  train_loss: 1.2411212921142578\n",
      "gone through 0/1008 validation examples | eval_loss: 1.353235125541687\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1235712766647339\n",
      "gone through 320/1008 validation examples | eval_loss: 0.9701411724090576\n",
      "gone through 480/1008 validation examples | eval_loss: 2.44977068901062\n",
      "gone through 640/1008 validation examples | eval_loss: 2.0980288982391357\n",
      "gone through 800/1008 validation examples | eval_loss: 2.2919814586639404\n",
      "gone through 960/1008 validation examples | eval_loss: 2.115605115890503\n",
      "After 5 epochs |  train_loss : 1.1856302073661318 |  eval_loss: 1.8026037263491796\n",
      "gone through 0/3008 training examples |  train_loss: 1.2649853229522705\n",
      "gone through 320/3008 training examples |  train_loss: 1.3250776529312134\n",
      "gone through 640/3008 training examples |  train_loss: 1.1077779531478882\n",
      "gone through 960/3008 training examples |  train_loss: 1.2074209451675415\n",
      "gone through 1280/3008 training examples |  train_loss: 1.140917181968689\n",
      "gone through 1600/3008 training examples |  train_loss: 1.1282334327697754\n",
      "gone through 1920/3008 training examples |  train_loss: 0.9652674794197083\n",
      "gone through 2240/3008 training examples |  train_loss: 1.2953078746795654\n",
      "gone through 2560/3008 training examples |  train_loss: 1.2165969610214233\n",
      "gone through 2880/3008 training examples |  train_loss: 1.391913652420044\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3480335474014282\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1183863878250122\n",
      "gone through 320/1008 validation examples | eval_loss: 0.9618241786956787\n",
      "gone through 480/1008 validation examples | eval_loss: 2.4556586742401123\n",
      "gone through 640/1008 validation examples | eval_loss: 2.107391834259033\n",
      "gone through 800/1008 validation examples | eval_loss: 2.296252965927124\n",
      "gone through 960/1008 validation examples | eval_loss: 2.128330945968628\n",
      "After 6 epochs |  train_loss : 1.1413317043730553 |  eval_loss: 1.807693460630992\n",
      "gone through 0/3008 training examples |  train_loss: 1.0050865411758423\n",
      "gone through 320/3008 training examples |  train_loss: 1.132364273071289\n",
      "gone through 640/3008 training examples |  train_loss: 1.1849515438079834\n",
      "gone through 960/3008 training examples |  train_loss: 0.9811368584632874\n",
      "gone through 1280/3008 training examples |  train_loss: 0.9499331116676331\n",
      "gone through 1600/3008 training examples |  train_loss: 1.1375631093978882\n",
      "gone through 1920/3008 training examples |  train_loss: 1.0248247385025024\n",
      "gone through 2240/3008 training examples |  train_loss: 1.1161705255508423\n",
      "gone through 2560/3008 training examples |  train_loss: 1.1684410572052002\n",
      "gone through 2880/3008 training examples |  train_loss: 1.1529251337051392\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3414572477340698\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1140531301498413\n",
      "gone through 320/1008 validation examples | eval_loss: 0.9557151794433594\n",
      "gone through 480/1008 validation examples | eval_loss: 2.4654629230499268\n",
      "gone through 640/1008 validation examples | eval_loss: 2.1174886226654053\n",
      "gone through 800/1008 validation examples | eval_loss: 2.304400682449341\n",
      "gone through 960/1008 validation examples | eval_loss: 2.139461040496826\n",
      "After 7 epochs |  train_loss : 1.1059429312640048 |  eval_loss: 1.8126271915814234\n",
      "gone through 0/3008 training examples |  train_loss: 1.1584073305130005\n",
      "gone through 320/3008 training examples |  train_loss: 1.0360468626022339\n",
      "gone through 640/3008 training examples |  train_loss: 1.0241200923919678\n",
      "gone through 960/3008 training examples |  train_loss: 1.1875768899917603\n",
      "gone through 1280/3008 training examples |  train_loss: 1.1910569667816162\n",
      "gone through 1600/3008 training examples |  train_loss: 1.1531635522842407\n",
      "gone through 1920/3008 training examples |  train_loss: 1.0066181421279907\n",
      "gone through 2240/3008 training examples |  train_loss: 1.1886391639709473\n",
      "gone through 2560/3008 training examples |  train_loss: 0.9628596901893616\n",
      "gone through 2880/3008 training examples |  train_loss: 1.1278003454208374\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3413230180740356\n",
      "gone through 160/1008 validation examples | eval_loss: 1.11244535446167\n",
      "gone through 320/1008 validation examples | eval_loss: 0.9479862451553345\n",
      "gone through 480/1008 validation examples | eval_loss: 2.4703640937805176\n",
      "gone through 640/1008 validation examples | eval_loss: 2.1208066940307617\n",
      "gone through 800/1008 validation examples | eval_loss: 2.309018611907959\n",
      "gone through 960/1008 validation examples | eval_loss: 2.1470320224761963\n",
      "After 8 epochs |  train_loss : 1.08889251313311 |  eval_loss: 1.8169552787901864\n",
      "gone through 0/3008 training examples |  train_loss: 1.2808794975280762\n",
      "gone through 320/3008 training examples |  train_loss: 1.1722484827041626\n",
      "gone through 640/3008 training examples |  train_loss: 0.9775460958480835\n",
      "gone through 960/3008 training examples |  train_loss: 1.1189738512039185\n",
      "gone through 1280/3008 training examples |  train_loss: 1.0252280235290527\n",
      "gone through 1600/3008 training examples |  train_loss: 1.2022467851638794\n",
      "gone through 1920/3008 training examples |  train_loss: 1.0312305688858032\n",
      "gone through 2240/3008 training examples |  train_loss: 1.126983404159546\n",
      "gone through 2560/3008 training examples |  train_loss: 0.9917402863502502\n",
      "gone through 2880/3008 training examples |  train_loss: 1.184827208518982\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3414486646652222\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1136246919631958\n",
      "gone through 320/1008 validation examples | eval_loss: 0.9479652047157288\n",
      "gone through 480/1008 validation examples | eval_loss: 2.4816651344299316\n",
      "gone through 640/1008 validation examples | eval_loss: 2.1277003288269043\n",
      "gone through 800/1008 validation examples | eval_loss: 2.3216323852539062\n",
      "gone through 960/1008 validation examples | eval_loss: 2.1530702114105225\n",
      "After 9 epochs |  train_loss : 1.067027930566605 |  eval_loss: 1.8231765731932625\n",
      "gone through 0/3008 training examples |  train_loss: 0.9351848363876343\n",
      "gone through 320/3008 training examples |  train_loss: 0.9553146362304688\n",
      "gone through 640/3008 training examples |  train_loss: 1.081006407737732\n",
      "gone through 960/3008 training examples |  train_loss: 1.169405460357666\n",
      "gone through 1280/3008 training examples |  train_loss: 1.1011593341827393\n",
      "gone through 1600/3008 training examples |  train_loss: 1.0083743333816528\n",
      "gone through 1920/3008 training examples |  train_loss: 1.0517526865005493\n",
      "gone through 2240/3008 training examples |  train_loss: 1.1798914670944214\n",
      "gone through 2560/3008 training examples |  train_loss: 1.2068854570388794\n",
      "gone through 2880/3008 training examples |  train_loss: 0.9249332547187805\n",
      "gone through 0/1008 validation examples | eval_loss: 1.3420438766479492\n",
      "gone through 160/1008 validation examples | eval_loss: 1.1123926639556885\n",
      "gone through 320/1008 validation examples | eval_loss: 0.9483404755592346\n",
      "gone through 480/1008 validation examples | eval_loss: 2.4845192432403564\n",
      "gone through 640/1008 validation examples | eval_loss: 2.1320111751556396\n",
      "gone through 800/1008 validation examples | eval_loss: 2.3246588706970215\n",
      "gone through 960/1008 validation examples | eval_loss: 2.15907621383667\n",
      "After 10 epochs |  train_loss : 1.0591172344507056 |  eval_loss: 1.8256676840403723\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_train_loss=0\n",
    "    model.train()\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels=batch['labels'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        loss =outputs.loss\n",
    "        total_train_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        if step%20==0:\n",
    "            print(f\"gone through {step*batch_size}/{len(train_dataloader)*batch_size} training examples |  train_loss: {loss.item()}\")\n",
    "            \n",
    "    avg_train_loss=(total_train_loss)/len(train_dataloader)\n",
    "\n",
    "    model.eval()\n",
    "    total_eval_loss=0\n",
    "    with torch.inference_mode():\n",
    "       for step,batch in enumerate(eval_dataloader):\n",
    "           \n",
    "           input_ids = batch['input_ids'].to(device)\n",
    "           attention_mask = batch['attention_mask'].to(device)\n",
    "           labels=batch['labels'].to(device)\n",
    "           outputs = model(input_ids=input_ids, attention_mask=attention_mask,labels=labels)\n",
    "           eval_loss =outputs.loss\n",
    "           total_eval_loss+=eval_loss.item()\n",
    "           \n",
    "           if step%10==0:\n",
    "               print(f\"gone through {step*batch_size}/{len(eval_dataloader)*batch_size} validation examples | eval_loss: {eval_loss.item()}\") \n",
    "               \n",
    "    avg_eval_loss=(total_eval_loss)/len(eval_dataloader)\n",
    "\n",
    "    print(f\"After {epoch+1} epochs |  train_loss : {avg_train_loss} |  eval_loss: {avg_eval_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  for step,batch in enumerate(test_dataloader):\n",
    "     \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels=batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,labels=labels)\n",
    "        test_loss =outputs.loss\n",
    "       \n",
    "\n",
    "        if step%5==0:\n",
    "            print(f\"gone through {step*batch_size}/{len(eval_dataloader)*batch_size} validation examples | eval_loss: {test_loss.item()}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
